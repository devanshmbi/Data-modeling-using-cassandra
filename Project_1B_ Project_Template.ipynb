{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Import all the necessary python modules necessary for the project \"\"\"\n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "\"\"\" First check the present working directory \"\"\"\n",
    "print(os.getcwd())\n",
    "\n",
    "\"\"\" Get current folder and subfolder for event data \"\"\"\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "\"\"\" Executing a for loop to fetch all the associated file path from the directory\"\"\"\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "full_data_rows_list = [] \n",
    "    \n",
    "\"\"\" Reading the CSV file and appending it into the list for every filepath in filepath list \"\"\"\n",
    "for f in file_path_list:\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)      \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Code to check the number of lines in the CSV \"\"\"\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" We will use cassandra library to connect to our instance \"\"\"\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "\"\"\" Creating session to establish connection and for executing queries \"\"\"\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" In this step, we will create a keyspace called sparkifydb in cassandra \"\"\"\n",
    "try:\n",
    "    session.execute(\"\"\" CREATE KEYSPACE IF NOT EXISTS sparkifydb \\\n",
    "    WITH REPLICATION = {'class' : 'SimpleStrategy', 'replication_factor': 1} \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"ERROR while creating the database\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" In this step, we will set our newly created keyspace for further development \"\"\"\n",
    "try:\n",
    "    session.set_keyspace(\"sparkifydb\")\n",
    "except Exception as e:\n",
    "    print(\" ERROR while connecting to the database\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" In this step we will create table for song_library based on artist,song title, track duration for each session\\\n",
    "We have used session_id as our partition column and item_in_session as our clustering column\\\n",
    "to get fetch data in sorted order \"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\" CREATE TABLE IF NOT EXISTS song_library_session \\\n",
    "    (session_id int, item_in_session int,artist text, song_title text, song_length float, \\\n",
    "    PRIMARY KEY (session_id, item_in_session)) \"\"\")\n",
    "except Exception as e:\n",
    "    print(\" ERROR while creating table\")\n",
    "    print (e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This step will read event_datafile_new csv, select particular columns as per schema and insert data into the select table\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \" INSERT INTO song_library_session (session_id, item_in_session,artist, song_title, song_length) \"\n",
    "        query = query + \"VALUES (%s,%s,%s,%s,%s)\"\n",
    "        session.execute(query, (int(line[8]),int(line[3]),line[0],line[9],float(line[5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: Faithless Song_title: Music Matters (Mark Knight Dub) Song_lenght: 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This query is to fetch data of artist, with thier tracks , length of the track for particular session,\\\n",
    "based on item_in_session and session_id\"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(\"\"\" select artist, song_title, song_length from song_library_session\\\n",
    "            where session_id = 338 and item_in_session = 4 \"\"\")\n",
    "    for row in rows:\n",
    "        print(\"Artist: \"+row.artist,\"Song_title: \"+row.song_title, \"Song_lenght: \"+str(row.song_length))\n",
    "except Exception as e:\n",
    "    print(\"ERROR occured while fetching data\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" In this step we will create table for user based on firstname, lastname and song track.\\\n",
    "We have used user_id and session_id as our partition column \\\n",
    "and item_in_session as our clustering column to get fetch data in sorted order \"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\" CREATE TABLE IF NOT EXISTS song_playlist_session \\\n",
    "    (user_id int,session_id int, item_in_session int,artist text, song_title text,firstName text, lastName text, \\\n",
    "    PRIMARY KEY ((user_id,session_id), item_in_session)) \"\"\")\n",
    "except Exception as e:\n",
    "    print(\" ERROR while creating table\")\n",
    "    print (e)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This step will read event_datafile_new csv, select particular columns as per schema and insert data into the select table\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \" INSERT INTO song_playlist_session \\\n",
    "        (user_id,session_id, item_in_session,artist, song_title, firstName, lastName ) \"\n",
    "        query = query + \"VALUES (%s,%s,%s,%s,%s,%s,%s)\"\n",
    "        session.execute(query, (int(line[10]),int(line[8]),int(line[3]),line[0],line[9],line[1],line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist: Down To The Bone song_title: Keep On Keepin' On first_name: Sylvie last_name: Cruz\n",
      "artist: Three Drives song_title: Greece 2000 first_name: Sylvie last_name: Cruz\n",
      "artist: Sebastien Tellier song_title: Kilometer first_name: Sylvie last_name: Cruz\n",
      "artist: Lonnie Gordon song_title: Catch You Baby (Steve Pitron & Max Sanna Radio Edit) first_name: Sylvie last_name: Cruz\n"
     ]
    }
   ],
   "source": [
    "\"\"\" This query is to fetch data for users, who listen to particular artist and songs of that artist for particular session,\\\n",
    "based on user_id and session_id\"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(\"\"\" select artist, song_title,firstName, lastName from song_playlist_session \\\n",
    "                            where user_id = 10 and session_id = 182 \"\"\")\n",
    "    for row in rows:\n",
    "         print(\"artist: \"+row.artist,\"song_title: \"+row.song_title,\"first_name: \"+row.firstname,\"last_name: \"+row.lastname)\n",
    "except Exception as e:\n",
    "    print(\"ERROR occured while fetching data\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" In this step we will create table for user based on firstname, lastname and song track.\\\n",
    "We have used song_title as our partition column and user_id as our clustering column for fast retrivals \"\"\"\n",
    "try:\n",
    "    session.execute(\"\"\" CREATE TABLE IF NOT EXISTS users_song_history \\\n",
    "    (song_title text, user_id int, firstName text, lastName text, \\\n",
    "    PRIMARY KEY (song_title, user_id) )\"\"\")\n",
    "except Exception as e:\n",
    "    print(\" ERROR while creating table\")\n",
    "    print (e) \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This step will read event_datafile_new csv, select particular columns as per schema and insert data into the select table\"\"\"\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader)\n",
    "    for line in csvreader:\n",
    "        query = \" INSERT INTO users_song_history (song_title, user_id, firstName, lastName ) \"\n",
    "        query = query + \"VALUES (%s,%s,%s,%s)\"\n",
    "        session.execute(query, (line[9],int(line[10]),line[1],line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name: Jacqueline last_name: Lynch\n",
      "first_name: Tegan last_name: Levine\n",
      "first_name: Sara last_name: Johnson\n"
     ]
    }
   ],
   "source": [
    "\"\"\" In this query we want users first name and lastname, who have listen to song_track 'All Hands Against His Own'.\"\"\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(\"\"\" select firstName,lastName from users_song_history \\\n",
    "    where song_title = 'All Hands Against His Own' \"\"\")\n",
    "    for row in rows:\n",
    "        print(\"first_name: \"+row.firstname,\"last_name: \"+row.lastname)\n",
    "except Exception as e:\n",
    "    print(\"ERROR occured while fetching data\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This step will drop the all the tables in the given keyspace\"\"\"\n",
    "try:\n",
    "    session.execute(\"\"\" DROP TABLE song_library_session \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"ERROR occured while dropping table song_library_session\")\n",
    "    print (e)\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\" DROP TABLE song_playlist_session  \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"ERROR occured while dropping table song_playlist_session\")\n",
    "    print (e)\n",
    "\n",
    "try:\n",
    "    session.execute(\"\"\" DROP TABLE users_song_history  \"\"\")\n",
    "except Exception as e:\n",
    "    print(\"ERROR occured while dropping table users_song_history\")\n",
    "    print (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
